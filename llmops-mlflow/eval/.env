# Ollama Configuration
ENABLE_OLLAMA=true
OLLAMA_MODEL=llama3.2
OLLAMA_BASE_URL=http://ollama:11434/v1
OLLAMA_API_KEY=ollama
OLLAMA_TEMPERATURE=0.0
OLLAMA_BATCH_SIZE=1
OLLAMA_MAX_TOKENS=2048
OLLAMA_HARDWARE=CPU

# vLLM Configuration
ENABLE_VLLM=false
VLLM_MODEL=deepseek
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_API_KEY=
VLLM_TEMPERATURE=0.0
VLLM_BATCH_SIZE=32
VLLM_MAX_TOKENS=2048
VLLM_HARDWARE=A100

# Judge Model Configuration
JUDGE_MODEL=llama3.2
JUDGE_TEMPERATURE=0.0